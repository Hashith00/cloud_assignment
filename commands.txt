## IMPORTANT COMMANDS ##

### FILE UPLOAD COMMANDS ###
scp -i cloud-project.pem tweet_classifier-1.0-SNAPSHOT.jar ubuntu@16.16.211.160:/home/ubuntu
scp -i tokyo_2020_tweets.csv ubuntu@16.16.211.160:/home/ubuntu

### Copy the file into the container namenode (Jar file in temp)
docker cp tweet_classifier-1.0-SNAPSHOT.jar namenode:/tmp/
docker cp tokyo_2020_tweets.csv namenode:/tmp/


### Go inside to the container bash
docker exec -it namenode /bin/bash

### Add the file into the hdfs file system
1. Create a dir
hdfs dfs -mkdir /user/root/input
2. Copy file
hdfs dfs -cp tokyo_2020_tweets.csv /user/root/input

### Go to the jar file location
cd /tmp

### Rnn the hadoop ( Need to in the folder where jar file is located)
hadoop jar tweet_classifier-1.0-SNAPSHOT.jar org.tweetClassifier.KeywordCounterDriver -D csv.text.column.index=10 input2 output


## DATA SET ##
https://www.kaggle.com/datasets/teamincribo/cyber-security-attacks/data